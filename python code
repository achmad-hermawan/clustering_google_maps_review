# Scraping data dari ulasan google maps

from serpapi import GoogleSearch
from urllib.parse import urlsplit, parse_qsl
import json
import pandas as pd

params = {
  "api_key": "d12ad9e8a239f30e500a1c2bb18c5256fa13e5966a17c3d39f66ccfadd830085",                    # API key dari serpAPI
  "engine": "google_maps_reviews",                                                                  # serpAPI search engine
  "hl": "id",                                                                                       # language of the search
  "data_id": "0x2e7a584c3f999547:0xf5f81e9fab2e1dfb"                                                # data id yang terletak di dalam URL Tempat Google Maps:di parameter kueri `data=`
}

search = GoogleSearch(params)


reviews = []

page_num = 0
while True:
    page_num += 1
    results = search.get_dict()
    if "error" in results:
        print(f"Error dari API: {results['error']}")
        break
    print(f"Extracting reviews from {page_num} page.")

    if not "error" in results:
        for result in results.get("reviews", []): # return an empty list [] if no reviews from the place
            reviews.append({
                "page": page_num,
                "name": result.get("user").get("name"),
                "link": result.get("user").get("link"),
                "thumbnail": result.get("user").get("thumbnail"),
                "rating": result.get("rating"),
                "date": result.get("date"),
                "snippet": result.get("snippet"),
                "images": result.get("images"),
                "local_guide": result.get("user").get("local_guide"),
                # other data
            })
    else:
        print(results["error"])
        break
    pagination = results.get("serpapi_pagination", {})

    if pagination and pagination.get("next") and pagination.get("next_page_token"):
        search.params_dict.update(dict(parse_qsl(urlsplit(pagination["next"]).query)))
    else:
        break
    if results.get("serpapi_pagination").get("next") and results.get("serpapi_pagination").get("next_page_token"):
        # split URL in parts as a dict and update search "params" variable to a new page that will be passed to GoogleSearch()
        search.params_dict.update(dict(parse_qsl(urlsplit(results["serpapi_pagination"]["next"]).query)))
        #search.params_dict.update(dict(parse_qsl(urlsplit(results["serpapi_pagination"]["next"]).query)))
        #print(result)
    else:
        break


print(json.dumps(reviews, indent=2, ensure_ascii=False))
df = pd.DataFrame(reviews)
df.to_csv(f"data.csv", index=False)
